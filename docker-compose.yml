
services:
  embedding-model:
    image: ollama/ollama:latest
    hostname: embedding-model
    ports:
      - "11434:11434"
    volumes:
      - ollama_embedding_data:/root/.ollama
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           capabilities: [gpu]
    #           count: all
    networks:
      - app-network
    post_start:
      - command: ollama pull all-minilm
    restart: unless-stopped
  
  # Comment this if you are using an external model
  text-completion-model:
    image: ollama/ollama:latest
    hostname: text-completion-model
    ports:
      - "11435:11435"
    volumes:
      - ollama_completion_data:/root/.ollama
    networks:
      - app-network
    environment:
      - OLLAMA_HOST=0.0.0.0:11435
    runtime: nvidia
    post_start:
      - command: ollama pull deepseek-r1:7b
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    hostname: qdrant
    ports:
      - "6333:6333" 
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage 
    environment:
      - QDRANT__VECTOR_SIZE=512
      - QDRANT__HUSH_MODE=true 
    restart: unless-stopped 
    networks:
      - app-network
  
  ai-agent-api:
    hostname: ai-agent-api
    build:
      context: ./AiAgent.API/.
      dockerfile: Dockerfile
      args:
        BUILD_CONFIGURATION: Development   
    env_file:
      - .env
    # environment:
    #   - OLLAMA_MODEL=${OLLAMA_MODEL}
    #   - OLLAMA_URI=${OLLAMA_URI}
    #   - QDRANT_HOSTAME=${QDRANT_HOSTNAME}
    #   - TEXT_COMPLETION_MODEL=${TEXT_COMPLETION_MODEL}
    #   - TEXT_COMPLETION_API_KEY=${TEXT_COMPLETION_API_KEY}
    #   - TEXT_COMPLETION_MODEL_ENDPOINT=${TEXT_COMPLETION_MODEL_ENDPOINT}
    ports:
      - "8080:8080"
      - "8081:8081"
    depends_on:
      - qdrant
      - embedding-model
      - text-completion-model
    restart: unless-stopped
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  qdrant_storage:
  ollama_completion_data:
  ollama_embedding_data:
  
